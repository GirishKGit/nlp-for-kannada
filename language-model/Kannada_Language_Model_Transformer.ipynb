{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-kannada/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import KannadaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.KannadaTokenizer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KannadaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KannadaTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/kannada_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/kannada_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '.',\n",
       " ',',\n",
       " '▁',\n",
       " '▁ಮತ್ತು',\n",
       " 'ದ',\n",
       " '▁ಈ',\n",
       " 'ಗಳು',\n",
       " 'ಯ',\n",
       " 'ಗಳ',\n",
       " 'ಗಳನ್ನು',\n",
       " 'ರ',\n",
       " '▁ಒಂದು',\n",
       " 'ವನ್ನು',\n",
       " '-',\n",
       " 'ವು',\n",
       " 'ನ',\n",
       " 'ರು']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25,000 is the vocab size that we chose in sentencepiece\n",
    "kannada_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=KannadaTokenizer, lang='kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=kannada_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁೧೦ ▁ಹಿರಿಯ ▁ಸದಸ್ಯರನ್ನು ▁ಸಭಾಧ್ಯಕ್ಷ ರು ▁ನೇಮಕ ▁ಮಾಡುತ್ತಾರೆ . ▁ಮೀರಾ ▁ಕುಮಾರ್ ▁ರವರು . ▁ಇವರು ▁ಲೋಕ ▁ಸಭೆಯ ▁ಮೊದಲ ▁ಮಹಿಳಾ ▁ಸಭಾ ದ್ಯ ಕ್ಷ ರು . ▁ಸಾಮಾನ್ಯ ▁ದಿನಗಳಲ್ಲಿ ▁ಲೋಕಸಭೆ ▁ಬೆಳಿಗ್ಗೆ ▁೧೧ ▁ರಿಂದ ▁ಮಧ್ಯಾಹ್ನ ▁ಒಂದರ ವರೆಗೆ , ▁ಮತ್ತೆ ▁ಮಧ್ಯಾಹ್ನ ▁ಎರಡರಿಂದ ▁ಸಂಜೆ ▁ಆರ ರ ▁ವರೆಗೆ ▁ಸೇರುತ್ತದೆ . ▁ಮೊದಲ ▁ಒಂದು ▁ಘಂಟೆ ▁ಪ್ರಶ್ನ ೋತ್ತರ ಗಳಿಗೆ ▁ಮೀಸಲ ಾಗಿ ಡ ಲಾಗಿರುತ್ತದೆ . ▁ಭಾರತ ▁ಸರ್ಕಾರದ ▁ಶಾಸಕಾಂಗ ದ ▁ಇನ್ನೊಂದು ▁ಸಭೆ ▁ರಾಜ್ಯ ಸಭೆ . ▁ಯಾವುದೇ ▁ಮಸೂದೆ ಗೆ ▁ಲೋಕಸಭೆ ▁ಒಪ್ಪಿಗೆ ▁ಇತ್ತ ▁ನಂತರ ▁ಅದು ▁ರಾಜ್ಯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>, ▁ಇತ್ತೀಚಿನ ▁ರಾಜಕೀಯ ▁ಶ್ರ ೋ ತೃ ವರ್ಗ ವೊಂದು ▁\" ಸಾ ಕರ್ ▁ಅಮ್ಮ ಂದಿ ರು \" ▁ಹಾಗೂ ▁\" &lt;unk&gt; na &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; ar ▁ಅಪ್ಪ ಂದಿ ರು \" ಗಳನ್ನು ▁ಒಳಗೊಂಡಿದೆ . \" ▁ಇದಲ್ಲದೇ ▁ದೇಹದ ಾರ್ ಢ ್ಯ , ▁ಆಹಾರ ಸೇ ವ ನಾ ▁ಆಯ್ಕೆ , ▁ಅಡ್ ರಿನ ಲಿನ್ ▁ ಜಂ ಕೀ ಗಳಂತಹ ▁ಮನೋ ಸ್ಫುಟ ತೆಯ ನ್ನಾ ಧರಿಸಿ ದ ▁ಗುಂಪು ವರ್ಗ ೀಕರಣ ವೂ ▁ನಡೆಯುತ್ತದೆ . . . ▁ಶ್ರ ೋ ತೃ ವರ್ಗದ ▁ಜತೆಗೇ ▁ಒಂದು</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁ಅಂಟು ಗಳನ್ನು ▁ಬಳಸಬಹುದು . ▁ತೊಗಟೆ ಬಟ್ಟೆ ಯನ್ನು ▁ತೊಗಟೆ ಯನ್ನು ▁ಮೃದು ▁ಮತ್ತು ▁ಚಪ್ಪಟೆ ಯ ಾಗುವವರೆಗೆ ▁ಜಜ್ಜಿ ▁ತಯಾರಿಸಲಾಗುತ್ತದೆ . ▁ಬಟ್ಟೆ ಗಳಿಗೆ ▁ಹಲವುವೇಳೆ ▁ಬಣ್ಣ ▁ಹಾಕಲಾಗುತ್ತದೆ , ▁ಮತ್ತು ▁ಬಟ್ಟೆಗಳು ▁ಬಹುತೇಕ ▁ಪ್ರತಿಯೊಂದು ▁ಬಣ್ಣದ ಲ್ಲೂ ▁ದೊರಕುತ್ತವೆ . ▁ಬಣ್ಣ ▁ಹಾಕುವ ▁ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ ▁ಹಲವುವೇಳೆ ▁ಪ್ರತಿ ▁ಪೌಂಡ್ ▁ಬಟ್ಟೆ ಗೆ ▁ಹಲವು ▁ಡ ಜ಼ ನ್ ▁ಗ್ಯಾಲ ನ್ ▁ನೀರು ▁ಬೇಕಾಗುತ್ತದೆ . ▁ಬಟ್ಟೆ ಗಳಲ್ಲಿ ▁ಬಣ್ಣ ವಿರುವ ▁ವಿನ್ಯಾಸಗಳನ್ನು ▁ಬೇರೆಬೇರೆ ▁ಬಣ್ಣದ ▁ನಾರು ಗಳನ್ನು ▁ಒಟ್ಟಾಗಿ ▁ನೇಯ್ದ ು , ▁ಸಿದ್ಧಪಡಿಸಿದ ▁ಬಟ್ಟೆ ಗೆ ▁ಬಣ್ಣ ವಿರುವ ▁ಹೊಲಿಗೆ ಗಳನ್ನು ▁ಸೇರಿಸಿ ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁ಆಕ್ರಮಣ ವನ್ನು ▁ಪಡೆಯಲು ▁ಪ್ರಯತ್ನಿಸ ಬಹುದು . ▁ಒಂದು ▁ವೇಳೆ ▁ಜೋಡಿ ಯು ▁ಒತ್ತಾಯ ವಾಗಿ ▁ಎತ್ತ ುವ ▁ಅಥವಾ ▁ ಶಟಲ್ ▁ಕಾಕ ನ್ನು ▁ತಿರುಗಿ ▁ಕಳುಹಿಸ ಲು ▁ಆ ▁ಸ್ಥಿತಿಯಲ್ಲಿ ▁ಅವರು ▁ಕಾಪಾಡಿಕೊಳ್ಳ ಲೇಬೇಕು : ▁ಎದುರಾಳಿ ಗಳ ▁ಹೊಡೆತ ಗಳನ್ನು ▁ಎದುರಿಸಲು ▁ಅವರು ▁ಅಂಕಣದ ▁ಪೂರ್ಣ ▁ಅಗಲ ವನ್ನು ▁ಕಾಪಾಡಲು ▁ಆಯ್ದುಕೊಳ್ಳ ಬೇಕಾಗುತ್ತದೆ . ▁ಡಬಲ್ಸ್ ▁ನಲ್ಲಿ , ▁ಗೊಂದಲ ▁ಮತ್ತು ▁ಸಂಘರ್ಷ ಣೆ ಗಳ ▁ಪ್ರಯೋಜನ ▁ಪಡೆಯಲು ▁ಆಟಗಾರರು ▁ಸಾಮಾನ್ಯವಾಗಿ ▁ಇಬ್ಬರು ▁ಆಟಗಾರರ ▁ಮಧ್ಯದ ▁ಮೈದಾನ ಕ್ಕೆ ▁ಎಸೆತ ▁ಹೊಡೆಯ ುತ್ತಾರೆ . ▁ಉನ್ನತ ▁ಮಟ್ಟದ ▁ಆಟದಲ್ಲಿ ▁ಹಿಂ ಗೈ ▁ಸರ್ವ ್</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ಟ್ರಿ ▁ತಾತ ▁ಕಥೆ ▁ಹೇಳ ್ ತಾರೆ ’ ▁ಕೃತಿಗೆ ▁ರಾಜ್ಯ ▁ಸರಕಾರದ ▁ಪ್ರಶಸ್ತಿ , ▁೧೯೭೪ ರಲ್ಲಿ ▁‘ ಅ ಜೇ ಯ ’ ▁ಮತ್ತು ▁೧೯೮೪ ರಲ್ಲಿ ▁‘ ಅ ದ ಮ್ಯ ’ ▁ಕೃತಿ ಗಳಿಗೆ ▁ರಾಜ್ಯ ▁ಸಾಹಿತ್ಯ ▁ಅಕಾಡಮಿ ▁ಪ್ರಶಸ್ತಿ , ▁೧೯೯೫ ರಲ್ಲಿ ▁ವಿಶ್ವೇಶ್ವರಯ್ಯ ▁ಎಂ ಜ ನಿಯ ರಿಂಗ್ ▁ಪ್ರತಿಷ್ಠಾನ ▁ಪ್ರಶಸ್ತಿ , ▁ಪತ್ರಿಕೋದ್ಯಮ ದ ▁ಸೇವೆಗಾಗಿ ▁ಕರ್ನಾಟಕ ▁ಜ್ಯೋತಿ ▁ಪ್ರಶಸ್ತಿ , ▁ಶಿವಮೊಗ್ಗ ದ ▁‘ ನಾ ವಿ ಕ ’ ▁ದಿನಪತ್ರಿಕೆ ಯ ▁ರಜತ ▁ಮಹೋತ್ಸವ ▁ಪ್ರಶಸ್ತಿ , ▁ರಂಗಭೂಮಿ ▁ಕೊಡುಗೆ ಗಾಗಿ ▁ಉದಯ ಕಲಾ ನಿ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(25000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.615072</td>\n",
       "      <td>6.631398</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>30:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.816413</td>\n",
       "      <td>5.845291</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>30:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.319539</td>\n",
       "      <td>5.318941</td>\n",
       "      <td>0.217899</td>\n",
       "      <td>30:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.022874</td>\n",
       "      <td>5.109102</td>\n",
       "      <td>0.230620</td>\n",
       "      <td>30:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.968721</td>\n",
       "      <td>5.071134</td>\n",
       "      <td>0.227887</td>\n",
       "      <td>30:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.858819</td>\n",
       "      <td>4.985186</td>\n",
       "      <td>0.234184</td>\n",
       "      <td>31:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.982770</td>\n",
       "      <td>4.906001</td>\n",
       "      <td>0.240021</td>\n",
       "      <td>31:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.840830</td>\n",
       "      <td>4.828884</td>\n",
       "      <td>0.247154</td>\n",
       "      <td>31:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.787942</td>\n",
       "      <td>4.759645</td>\n",
       "      <td>0.254573</td>\n",
       "      <td>31:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.768596</td>\n",
       "      <td>4.683124</td>\n",
       "      <td>0.262986</td>\n",
       "      <td>31:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.586790</td>\n",
       "      <td>4.598897</td>\n",
       "      <td>0.270544</td>\n",
       "      <td>31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.556510</td>\n",
       "      <td>4.511861</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>31:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.338057</td>\n",
       "      <td>4.416551</td>\n",
       "      <td>0.291697</td>\n",
       "      <td>31:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.300632</td>\n",
       "      <td>4.341498</td>\n",
       "      <td>0.299958</td>\n",
       "      <td>31:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.033594</td>\n",
       "      <td>4.283917</td>\n",
       "      <td>0.306986</td>\n",
       "      <td>31:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.167098</td>\n",
       "      <td>4.214736</td>\n",
       "      <td>0.316061</td>\n",
       "      <td>31:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.074809</td>\n",
       "      <td>4.171689</td>\n",
       "      <td>0.321340</td>\n",
       "      <td>31:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.045734</td>\n",
       "      <td>4.144122</td>\n",
       "      <td>0.324783</td>\n",
       "      <td>31:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.911547</td>\n",
       "      <td>4.129798</td>\n",
       "      <td>0.326882</td>\n",
       "      <td>31:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.927034</td>\n",
       "      <td>4.126805</td>\n",
       "      <td>0.327262</td>\n",
       "      <td>31:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.1402001976966858.\n",
      "Better model found at epoch 1 with accuracy value: 0.1830381155014038.\n",
      "Better model found at epoch 2 with accuracy value: 0.21789920330047607.\n",
      "Better model found at epoch 3 with accuracy value: 0.23062016069889069.\n",
      "Better model found at epoch 5 with accuracy value: 0.23418447375297546.\n",
      "Better model found at epoch 6 with accuracy value: 0.2400212436914444.\n",
      "Better model found at epoch 7 with accuracy value: 0.24715350568294525.\n",
      "Better model found at epoch 8 with accuracy value: 0.2545730769634247.\n",
      "Better model found at epoch 9 with accuracy value: 0.26298603415489197.\n",
      "Better model found at epoch 10 with accuracy value: 0.27054381370544434.\n",
      "Better model found at epoch 11 with accuracy value: 0.28020015358924866.\n",
      "Better model found at epoch 12 with accuracy value: 0.29169654846191406.\n",
      "Better model found at epoch 13 with accuracy value: 0.2999584972858429.\n",
      "Better model found at epoch 14 with accuracy value: 0.3069860339164734.\n",
      "Better model found at epoch 15 with accuracy value: 0.3160612881183624.\n",
      "Better model found at epoch 16 with accuracy value: 0.3213404417037964.\n",
      "Better model found at epoch 17 with accuracy value: 0.3247831463813782.\n",
      "Better model found at epoch 18 with accuracy value: 0.32688194513320923.\n",
      "Better model found at epoch 19 with accuracy value: 0.3272615969181061.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"ಚುನಾವಣೆ ಬಂತೆಂದರೆ\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ಚುನಾವಣೆ ಬಂತೆಂದರೆ ▁ಕಾನೂನ ೆಂದೇ ▁ಅರ್ಥ . ಕೆಲವು ▁ಸಲ ▁ಮತದಾರರ ಿಗೆ ▁ಅವರ ▁ಸ್ವಂತ ▁ಮನೆ ಯನ್ನೇ ▁ಆಯ್ಕೆ ▁ಮಾಡಿಕೊಂಡು ▁ಅವರ ▁ವೈಯಕ್ತಿಕ ▁ದಾಖಲೆ ಗಳಿಗೆ ▁ಸಂಬಂಧಿಸಿದಂತೆ ▁ಅಥವಾ ▁ಅವರ ▁ಫ್ಯಾ ನ್ ▁ಗಳ ▁ಸಂಬಂಧ ದಿಂದ ▁ಇದನ್ನು ▁ಚಿತ್ರ ಿಸಲಾಗುತ್ತದೆ . ▁x x b os ▁ . ▁x x b os\n",
      "ಚುನಾವಣೆ ಬಂತೆಂದರೆ ▁ಒಂದು ▁ಅವಧಿಗೆ ▁ಅಥವಾ ▁ಒಂದು ▁ಪ್ರಮುಖ ▁ಮೌಲ್ಯ ಕ್ಕೆ ▁ನೀಡಿದ ▁ಹೆಚ್ಚು ▁ನಿರ್ದಿಷ್ಟ ▁ಪ್ರಾಮುಖ್ಯತೆ . ▁ಸಾರ್ವಭೌಮ ▁ಭೂಪಟ ವು ▁ಒಂದು ▁ಏಕ ▁ಅಥವಾ ▁ಏಕ ▁ಆಯಾಮ ವಾದ ▁ಒಂದು ▁ಪರ್ಯಾಯ ▁ಪದ ವಾಗಿದೆ . ▁ಇದು ▁ಒಂದು ▁ಏಕ ಲೋಹ ▁ಆಧಾರಿತ ▁ಮತ್ತು ▁ಒಂದು ▁ಏಕ ಲೋಹ ▁ರೂಪದ ▁ಒಂದು ▁ಏಕ - ಲೋಹ\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.979581490164826"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(4.126805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-kannada/language-model')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'KannadaDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 410])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 410)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.266174</td>\n",
       "      <td>0.124870</td>\n",
       "      <td>0.254980</td>\n",
       "      <td>0.076422</td>\n",
       "      <td>0.188704</td>\n",
       "      <td>-0.031145</td>\n",
       "      <td>0.093035</td>\n",
       "      <td>0.253179</td>\n",
       "      <td>-0.196177</td>\n",
       "      <td>0.070887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363125</td>\n",
       "      <td>0.084763</td>\n",
       "      <td>-0.103276</td>\n",
       "      <td>-0.189418</td>\n",
       "      <td>-0.171104</td>\n",
       "      <td>0.255654</td>\n",
       "      <td>-0.344671</td>\n",
       "      <td>-0.271971</td>\n",
       "      <td>-0.144279</td>\n",
       "      <td>-0.257397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238252</td>\n",
       "      <td>-0.282687</td>\n",
       "      <td>0.124436</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>0.091160</td>\n",
       "      <td>0.090165</td>\n",
       "      <td>0.246489</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>-0.043298</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129805</td>\n",
       "      <td>-0.086011</td>\n",
       "      <td>-0.160074</td>\n",
       "      <td>-0.168352</td>\n",
       "      <td>-0.110117</td>\n",
       "      <td>-0.174372</td>\n",
       "      <td>-0.115746</td>\n",
       "      <td>0.240195</td>\n",
       "      <td>0.226009</td>\n",
       "      <td>-0.159793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227181</td>\n",
       "      <td>-0.282572</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.038089</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.092068</td>\n",
       "      <td>0.249090</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>-0.048689</td>\n",
       "      <td>0.137233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123515</td>\n",
       "      <td>-0.087392</td>\n",
       "      <td>-0.146289</td>\n",
       "      <td>-0.165301</td>\n",
       "      <td>-0.122987</td>\n",
       "      <td>-0.168759</td>\n",
       "      <td>-0.113720</td>\n",
       "      <td>0.238042</td>\n",
       "      <td>0.222497</td>\n",
       "      <td>-0.157990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.104529</td>\n",
       "      <td>0.227181</td>\n",
       "      <td>0.338077</td>\n",
       "      <td>-0.119556</td>\n",
       "      <td>-0.011237</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.154692</td>\n",
       "      <td>0.207726</td>\n",
       "      <td>-0.327809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338531</td>\n",
       "      <td>-0.384790</td>\n",
       "      <td>0.199326</td>\n",
       "      <td>0.071135</td>\n",
       "      <td>0.306256</td>\n",
       "      <td>-0.069827</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>-0.126048</td>\n",
       "      <td>-0.159682</td>\n",
       "      <td>-0.121997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>-0.114821</td>\n",
       "      <td>-0.094656</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>-0.040027</td>\n",
       "      <td>0.365885</td>\n",
       "      <td>-0.042614</td>\n",
       "      <td>0.175889</td>\n",
       "      <td>0.324687</td>\n",
       "      <td>-0.139640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286693</td>\n",
       "      <td>-0.151834</td>\n",
       "      <td>0.101049</td>\n",
       "      <td>-0.020544</td>\n",
       "      <td>0.166170</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>0.043354</td>\n",
       "      <td>-0.115249</td>\n",
       "      <td>-0.123124</td>\n",
       "      <td>0.162722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.266174  0.124870  0.254980  0.076422  0.188704 -0.031145  0.093035   \n",
       "1  0.238252 -0.282687  0.124436  0.035976  0.091160  0.090165  0.246489   \n",
       "2  0.227181 -0.282572  0.125654  0.038089  0.093775  0.092068  0.249090   \n",
       "3 -0.104529  0.227181  0.338077 -0.119556 -0.011237  0.066875  0.005192   \n",
       "4  0.245394 -0.114821 -0.094656 -0.037495 -0.040027  0.365885 -0.042614   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0  0.253179 -0.196177  0.070887  ...  0.363125  0.084763 -0.103276 -0.189418   \n",
       "1  0.026561 -0.043298  0.134949  ...  0.129805 -0.086011 -0.160074 -0.168352   \n",
       "2  0.026331 -0.048689  0.137233  ...  0.123515 -0.087392 -0.146289 -0.165301   \n",
       "3  0.154692  0.207726 -0.327809  ...  0.338531 -0.384790  0.199326  0.071135   \n",
       "4  0.175889  0.324687 -0.139640  ...  0.286693 -0.151834  0.101049 -0.020544   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0 -0.171104  0.255654 -0.344671 -0.271971 -0.144279 -0.257397  \n",
       "1 -0.110117 -0.174372 -0.115746  0.240195  0.226009 -0.159793  \n",
       "2 -0.122987 -0.168759 -0.113720  0.238042  0.222497 -0.157990  \n",
       "3  0.306256 -0.069827  0.067686 -0.126048 -0.159682 -0.121997  \n",
       "4  0.166170  0.048973  0.043354 -0.115249 -0.123124  0.162722  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      .\n",
       "4      ,"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2383, -0.2827,  0.1244,  0.0360,  0.0912,  0.0902,  0.2465,  0.0266,\n",
       "        -0.0433,  0.1349,  0.0594, -0.2040, -0.0694, -0.0958, -0.2422,  0.7497,\n",
       "        -0.2222, -0.1744,  0.1367,  0.2172, -0.0157, -0.1982, -0.0514, -0.2764,\n",
       "        -0.0066, -0.3184, -0.0118, -0.0459,  0.1500, -0.2728, -0.4488, -0.2391,\n",
       "        -0.1727, -0.1473, -0.0019,  0.1124, -0.0430,  0.1053,  0.2952,  0.0550,\n",
       "         0.2364,  0.0728,  0.3142, -0.0295,  0.2594, -0.0781,  0.0229, -0.0894,\n",
       "         0.0261,  0.3227, -0.1377, -0.3820,  0.1947,  0.0861, -0.0137, -0.1768,\n",
       "        -0.0227, -0.0366, -0.0450,  0.1080, -0.1580,  0.5235,  0.2110,  0.1552,\n",
       "         0.3663, -0.3590,  0.1594, -0.0984, -0.1029,  0.3003,  0.4413,  0.0685,\n",
       "        -0.1884,  0.2368, -0.1354, -0.2102,  0.3959,  0.3352,  0.0309,  0.2807,\n",
       "         0.1557, -0.3302,  0.0095,  0.1406, -0.1899, -0.1689, -0.1317, -0.0638,\n",
       "        -0.2040,  0.5297, -0.1660,  0.0796, -0.0847,  0.2343,  0.1887,  0.1286,\n",
       "        -0.1005, -0.4086,  0.2331, -0.0455, -0.5124,  0.2597, -0.0718, -0.1144,\n",
       "         0.2772,  0.0719, -0.0153,  0.1429, -0.1160,  0.0274, -0.0716,  0.0305,\n",
       "        -0.0984, -0.2950, -0.0237,  0.0106, -0.1627, -0.1023, -0.5228,  0.2154,\n",
       "         0.1105,  0.1261,  0.1240, -0.0272, -0.1876, -0.0548,  0.2030, -0.2117,\n",
       "         0.0176, -0.1000,  0.0189, -0.1815, -0.1810, -0.0336,  0.0102,  0.0020,\n",
       "         0.1367,  0.0530, -0.0873,  0.2536, -0.1142, -0.4073, -0.0442,  0.0368,\n",
       "        -0.1240, -0.1367, -0.3833,  0.0386,  0.1663, -0.1110,  0.0535,  0.3689,\n",
       "        -0.1272,  0.1212, -0.1675, -0.1598,  0.1690,  0.0070, -0.4913, -0.2235,\n",
       "         0.0089,  0.0986,  0.0738,  0.2114,  0.1954, -0.0126, -0.3405,  0.0566,\n",
       "        -0.0569, -0.2437, -0.1082, -0.2573, -0.3497,  0.2966,  0.1742,  0.3057,\n",
       "        -0.0647, -0.0360, -0.1635,  0.2132, -0.6171, -0.6647,  0.1197,  0.1644,\n",
       "        -0.2856, -0.2009, -0.4498, -0.1934,  0.2243, -0.1911, -0.2958,  0.0463,\n",
       "         0.3035,  0.0729, -0.0173, -0.2243, -0.3014, -0.0984,  0.3050, -0.3130,\n",
       "         0.1757, -0.0574, -0.1054,  0.1678, -0.2089, -0.0747, -0.0125, -0.0834,\n",
       "         0.0550, -0.0992,  0.2423, -0.1827, -0.1439, -0.1339,  0.0098,  0.0170,\n",
       "         0.2540,  0.0652, -0.1912,  0.2768, -0.0742,  0.0316,  0.0058, -0.3899,\n",
       "        -0.2568,  0.1762,  0.0875,  0.0787, -0.1330,  0.0400, -0.0511, -0.1095,\n",
       "         0.1051, -0.0849, -0.0737,  0.8506, -0.2376, -0.0928, -0.2696,  0.0462,\n",
       "        -0.2180, -0.1644, -0.1986,  0.2417, -0.1066, -0.0207,  0.2574,  0.2226,\n",
       "        -0.1124, -0.3139,  0.1147,  0.1933,  0.3349,  0.0915, -0.0366,  0.0599,\n",
       "         0.0333,  0.0444,  0.0188,  0.0245,  0.0640, -0.2858, -0.2318, -0.0103,\n",
       "        -0.3998, -0.0254, -0.0045,  0.1308,  0.3552, -0.1953, -0.1845, -0.0116,\n",
       "         0.3049,  0.1854,  0.1158,  0.0162, -0.2237,  0.0721,  0.0213, -0.1101,\n",
       "         0.1051,  0.6171, -0.1908,  0.0026,  0.0344, -0.1173,  0.0857,  0.0540,\n",
       "        -0.5776,  0.0976, -0.5095,  0.3528, -0.1386, -0.5286,  0.4171,  0.1049,\n",
       "        -0.2275, -0.2753,  0.3922,  0.2240,  0.0158,  0.1431,  0.3620,  0.2358,\n",
       "         0.0601, -0.0193,  0.1072,  0.2865,  0.3451, -0.0684,  0.2532,  0.4599,\n",
       "        -0.1550, -0.2028, -0.0210, -0.5135, -0.0349,  0.0543,  0.1754,  0.1256,\n",
       "        -0.1215, -0.2768,  0.0828, -0.2170,  0.1879,  0.2175, -0.0219, -0.0882,\n",
       "        -0.0481,  0.3538, -0.2570, -0.3898, -0.0880,  0.1575,  0.0521,  0.1657,\n",
       "        -0.1930,  0.2159, -0.0974, -0.0029,  0.3343,  0.0945,  0.4707,  0.3095,\n",
       "         0.0100,  0.2858,  0.0631,  0.0536,  0.3998, -0.2307, -0.2200,  0.1855,\n",
       "        -0.2327, -0.2722, -0.0324,  0.3253,  0.1246,  0.2420, -0.0159,  0.0286,\n",
       "        -0.0492, -0.3651,  0.0016, -0.0162,  0.0859,  0.1586,  0.3419, -0.0192,\n",
       "        -0.1395,  0.1448,  0.1374, -0.0147,  0.0137,  0.2917,  0.2144, -0.2793,\n",
       "        -0.1395,  0.1386,  0.0013,  0.1677,  0.1406, -0.3394,  0.1510,  0.3186,\n",
       "        -0.1164, -0.0223,  0.0792, -0.0937, -0.6000, -0.0511, -0.1156,  0.0125,\n",
       "        -0.0423,  0.4938, -0.0306, -0.1645, -0.0337, -0.0085,  0.3379, -0.0964,\n",
       "         0.1298, -0.0860, -0.1601, -0.1684, -0.1101, -0.1744, -0.1157,  0.2402,\n",
       "         0.2260, -0.1598], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
